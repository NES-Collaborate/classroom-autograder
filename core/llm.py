"""Module for LLM integration."""

from pathlib import Path

import magentic

from core import logger
from models import FeedbackResult, UserProfile


@magentic.prompt(
    """Voc√™ √© um professor experiente avaliando o trabalho do aluno {student_name}.
Seu objetivo √© fornecer um feedback personalizado, construtivo e motivador.

## Diretrizes para o feedback:
- Mantenha um tom amig√°vel mas profissional
- Use emojis ocasionalmente para tornar o feedback mais engajador
- Referencie partes espec√≠ficas do trabalho do aluno
- Forne√ßa exemplos concretos de como melhorar, especialmente para c√≥digo
- Priorize coment√°rios pr√°ticos e acion√°veis
- Evite repetir o t√≠tulo da atividade ou informa√ß√µes que j√° estar√£o no template HTML
- Seja espec√≠fico sobre o que est√° bom e o que precisa melhorar

## Formato do feedback:
### Pontos Positivos ‚úÖ
- Liste aqui os aspectos bem executados, com exemplos espec√≠ficos
- Destaque as √°reas onde o aluno demonstrou compreens√£o

### Oportunidades de Melhoria üîç
- Identifique √°reas espec√≠ficas para desenvolvimento
- Explique claramente o que poderia ser melhorado e por qu√™

### Sugest√µes Pr√°ticas üí°
- Ofere√ßa exemplos concretos de como melhorar
- Para c√≥digo, forne√ßa snippets corrigidos
- Sugira recursos ou t√©cnicas espec√≠ficas que possam ajudar

## Atribui√ß√£o de Nota:
Avalie o trabalho de acordo com os crit√©rios fornecidos, atribuindo uma nota justa que reflita tanto as conquistas quanto as √°reas de melhoria.

## Trabalho do aluno:
{context}

## Crit√©rios de avalia√ß√£o:
{criteria}
""",
    model=magentic.OpenaiChatModel("gpt-4o-mini"),
)
def evaluate_student_submissions(
    context: str, criteria: str, student_name: str
) -> FeedbackResult:
    """Avalia submiss√µes de alunos usando LLM com feedback personalizado."""
    ...


def create_feedback(
    student: UserProfile,
    context: str,
    criteria_file: Path,
) -> FeedbackResult | str:
    """Cria feedback para uma submiss√£o."""
    try:
        criteria = criteria_file.read_text(encoding="utf-8")

        with logger.status("Gerando feedback personalizado..."):
            # Gera o feedback usando LLM
            result = evaluate_student_submissions(context, criteria, student.full_name)

        logger.info(
            f"[dim]Feedback gerado para {student.full_name}, Nota: {result.grade}[/dim]"
        )
        return result

    except Exception as e:
        logger.error(f"Erro ao gerar feedback: {str(e)}")
        return f"# Erro na Avalia√ß√£o\n\nN√£o foi poss√≠vel gerar o feedback automaticamente.\nErro: {str(e)}"


@magentic.prompt(
    """Voc√™ √© um professor especialista em design de avalia√ß√µes educacionais.

Sua tarefa √© criar crit√©rios de avalia√ß√£o detalhados, objetivos e justos para a atividade descrita abaixo.

Os crit√©rios devem:
- Ser organizados em categorias claras (ex: funcionalidade, estrutura, estilo)
- Incluir uma distribui√ß√£o equilibrada de pontos
- Fornecer m√©tricas espec√≠ficas para cada n√≠vel de desempenho
- Ser facilmente aplic√°veis por outros professores

Para atividades de programa√ß√£o, inclua crit√©rios sobre:
- Funcionalidade do c√≥digo
- Estrutura e organiza√ß√£o
- Efici√™ncia e otimiza√ß√£o
- Documenta√ß√£o e legibilidade
- Tratamento de erros (quando aplic√°vel)

Enunciado da atividade:
{context}""",
    model=magentic.OpenaiChatModel("gpt-4o-mini"),
)
def generate_criteria(context: str) -> str:
    """Gera crit√©rios de avalia√ß√£o detalhados usando LLM."""
    ...
